# Overview of this Project

The purpose of this project was to create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. Using Python, Pandas, the ETL process, and code refactoring, a function that reads in the three data files and creates three separate DataFrames was created. The Wikipedia data merged with the Kaggle metadata. While extracting the IMDb IDs using a regular expression string and dropping duplicates, use a try-except block to catch errors. The Kaggle metadata DataFrame with the Wikipedia movies DataFrame to create the movies_df DataFrame were merged. Finally, the MovieLens rating data DataFrame merged with the movies_df DataFrame to create the movies_with_ratings_df. Lastly, the movies_df DataFrame and MovieLens rating CSV data was imported to a SQL database.